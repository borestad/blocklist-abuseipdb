#!/usr/bin/env bash

set -e

# Setup
cd "$(dirname $0)"

GIT_ROOT=$(git rev-parse --show-toplevel)
DB_PATH=$GIT_ROOT/db
mkdir -p $DB_PATH
TEMPFILE=$(mktemp)
TEMPDIR=$(mktemp -d)
SOURCEDIR=$GIT_ROOT/.cron/sources
mkdir -p $SOURCEDIR

function check-block() {
  local URL="$1"
  curl -sL "$URL" | \
    grepip | xargs -n1 $GIT_ROOT/.cron/scripts/abuseipdb-check | jq 'select(.numReports > 1)' | grepip
}

cd $TEMPDIR

# Debug
echo "Public IP:"
echo $(timeout 2s curl --no-progress-meter ipv4.icanhazip.com)
echo

echo 'âœ” Debug...'
date '+%Y/%m/%d %H:%M:%S'
bkt --ttl=6h -- date '+%Y/%m/%d %H:%M:%S'
echo


echo 'âœ” Download abuseipdb...'
# Use a TTL of ~2.5 hours (~ 9/10 requests if verified webmaster)
bkt --ttl=180min -- curl https://api.abuseipdb.com/api/v2/blacklist \
  --get \
  --max-time 10 \
  --user-agent "" \
  --no-progress-meter \
  -d confidenceMinimum=100 \
  -d limit=9999999 \
  -H "Key: $ABUSEIPDB_TOKEN" \
  -H "Accept: text/plain" \
  --fail \
  -w "\n" \
  -o SOURCE.abuseipdb || true

echo 'âœ” Download & decorate with extra sources ...'
echo '#2: abuseipdb.tmiland.com/'
curl -sL https://abuseipdb.tmiland.com/abuseipdb.txt \
  --compressed --max-time 10 -G -sL --fail -o SOURCE.tmiland || true

echo '#3: LittleJake'
curl -sL https://raw.githubusercontent.com/LittleJake/ip-blacklist/main/abuseipdb_blacklist_ip_score_100.txt \
  --compressed --max-time 10 -G -sL --fail -o SOURCE.jake || true

#
echo '#4: ðŸ’© Whitelisted scanners'
check-block https://raw.githubusercontent.com/borestad/iplists/refs/heads/main/paloaltonetworks/paloaltonetworks.ipv4 >| SOURCE.paloaltonetworks || true
check-block https://raw.githubusercontent.com/borestad/iplists/refs/heads/main/censys/censys.ipv4 >| SOURCE.censys || true
check-block https://raw.githubusercontent.com/borestad/iplists/refs/heads/main/project-sonar/project-sonar.ipv4 >| SOURCE.project-sonar || true
check-block https://raw.githubusercontent.com/borestad/iplists/refs/heads/main/openai/gptbot.ipv4 >| SOURCE.gptbot || true
check-block https://raw.githubusercontent.com/borestad/firehol-mirror/refs/heads/main/dshield.netset >| SOURCE.dshield || true

curl -sL https://raw.githubusercontent.com/borestad/iplists/refs/heads/main/modat/modat.ipv4 \
  --compressed --max-time 10 -G -sL --fail -o SOURCE.modat || true

echo '#7: Broken ASNS'
$GIT_ROOT/.cron/jobs/abuseipdb/asn | \
  xargs -I% $GIT_ROOT/.cron/scripts/abuseipdb-check % | jq 'select(.numReports > 1)' | grepip >| SOURCE.broken-asns || true

# Redundancy:
# - Separate private cache (1 of 5 requests / day) to avoid breaking the 5 free run limit / day
# - If above urls fail due to github actions being flaky, still have somewhat fresh data.
# echo 'âœ” Download from cache'
# echo '#8: Private cache'
# curl "$CRONSRC_URL" --compressed --max-time 10 -G -sL -w "\n\n" --fail -o SOURCE.9 || true

echo '#9: Private honeypots with verified abuse score'
TODAY="$(date +%Y-%m-%d)"

curl "$HONEYPOT1_URL/$TODAY/$TODAY.ipv4?who?$HP_ACCESS_TOKEN" --compressed --max-time 10 -G -sL -w "\n\n" --fail -o SOURCE.hp1 || true
cat SOURCE.hp1 | grepip | iprange - -1 --except $GIT_ROOT/abuseipdb-s100-1d.ipv4 || true

# curl "$HONEYPOT2_URL/$TODAY.ipv4" --compressed --max-time 10 -G -sL -w "\n\n" --fail -o TEMPFILE.222 || true
# cat TEMPFILE.222 | grepip | iprange - -1 --except $GIT_ROOT/abuseipdb-s100-1d.ipv4 || true

# curl "$HONEYPOT3_URL/$TODAY/$TODAY.ipv4" --compressed --max-time 10 -G -sL -w "\n\n" --fail -o TEMPFILE.333 || true
# cat TEMPFILE.333 | grepip | iprange - -1 --except $GIT_ROOT/abuseipdb-s100-1d.ipv4 || true

curl "$HONEYPOT4_URL/$TODAY/$TODAY.ipv4?who=$HP_ACCESS_TOKEN" --compressed --max-time 10 -G -sL -w "\n\n" --fail -o SOURCE.hp4 || true
cat SOURCE.hp4 | grepip | iprange - -1 --except $GIT_ROOT/abuseipdb-s100-1d.ipv4 || true


# echo '#10: Whitelists'
# dig +short @1.1.1.1 raw.githubusercontent.com | grepip | iprange -1 | sponge WHITELIST.githubusercontent || true

# echo 'âœ” Stats'
# for FILE in TEMPFILE.*; do printf "$FILE "; wc -l < $FILE; done

echo 'âœ” Squash all sources (by design: fail if no sources worked)'
grep -h "" SOURCE.* >> $TEMPFILE

echo 'For easier debugging. Save temp sources'
test -d $SOURCEDIR && rm -f $SOURCEDIR/*
for file in SOURCE.*; do
  mv -v "$file" $SOURCEDIR/${file}.ipv4
done

echo 'âœ” Validate: Clean comments'
cat $TEMPFILE | shfmt -mn | sponge $TEMPFILE

echo 'âœ” Validate: Extract ipv6 data'
  grep ':' $TEMPFILE | sort | tac | cidr-merger | sponge $TEMPFILE.ipv6

echo 'âœ” Validate: Extract ipv4 data'
  grep -v ":" $TEMPFILE | \
  iprange - -1 --except $GIT_ROOT/.cron/jobs/abuseipdb/bogons.ipv4 \
  > $TEMPFILE.ipv4

# 3. Validate data
LINES=`wc -l < $TEMPFILE.ipv4`
if [[ "$LINES" -gt "1000" ]]; then
  echo "âœ” Validate: File contains: $LINES lines"
  mv $TEMPFILE.ipv4 $DB_PATH/abuseipdb-s100-latest.ipv4
  mv $TEMPFILE.ipv6 $DB_PATH/abuseipdb-s100-latest.ipv6
else
  echo "âŒ Validation failed"
  echo
  echo "-----------------------------------------------------"
  cat $TEMPFILE
  echo "-----------------------------------------------------"
  cat $TEMPFILE.ipv4
  echo "-----------------------------------------------------"
  exit 1
fi

echo
echo 'âœ” Aggregate: Create folders'
DATE=$(date +%F)
DATE_DIR=$DB_PATH/$DATE
mkdir -pv $DATE_DIR && cd $DATE_DIR

echo 'âœ” Aggregate: Copy latest to correct date folder'
cp $DB_PATH/abuseipdb-s100-latest.ipv4 "$DATE_DIR/tmp-$(date +%H-%m-%S).ipv4"
cp $DB_PATH/abuseipdb-s100-latest.ipv6 "$DATE_DIR/tmp-$(date +%H-%m-%S).ipv6"

echo 'âœ” Aggregate: Squash ipv4 data'
iprange -1 *.ipv4 | sponge $(date +%Y-%m-%d).ipv4

echo 'âœ” Aggregate: Squash ipv6 data'
cat *.ipv6 | grep ':' | sort | uniq | sort | sponge $(date +%Y-%m-%d).ipv6

echo
echo 'âœ” Cleanup: Remove temp files'
rm -f tmp*.ipv4
rm -f tmp*.ipv6
